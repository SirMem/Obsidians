---
Project: "[[4-Archives/Stopping/操作系统|操作系统]]"
Status: 
tags:
  - Resources
Deadline: 
CreateTime: 2024-04-27
Connected: 
---
# 物理和虚拟寻址
## 物理寻址
计算机系统的主存被组织成一个由 M 个连续的字节大小的单元组成的数组 。 每字节都有 一 个唯一的物理地址 (Physical Address ,PA) 。 第一个字节的地址为 0, 接下来的字节地址为 1, 再下一个为 2依此类推。这种方式称为物理寻址
![[eDqKLfGvNLCndwWt-98d22dba-0b0a-de08-a50a-70870386c883.png|374]]
## 虚拟寻址
使用虚拟寻址， CPU 通过生成一个虚拟地址 (Virtual Address, VA)来访问主存，这个虚拟地址在被送到内存之前先转换成适当的物理地址。将一个虚拟地址转换为物理地址的任务叫做地址翻译(address translation) 

地址翻译需要 CPU 硬件和操作系统之间的紧密合作 。 CPU 芯片上叫做内存管理单元 (Memory Management Unit,MMU)的专用硬件，利用存放在主存中的查询表来动态翻译虚拟地址，该表的内容由操作系统管理。

![[eDqKLfGvNLCndwWt-1870dfc0-db57-b9fe-f762-2e0e08ba11bb.png|644]]

# 地址空间
地址空间 (address space) 是一个非负整数地址的有序集合：{0,1,2}
如果地址空间中的整数是连续的，那么我们说它是一个线性地址空间 (linear address space) 。

## 虚拟地址空间
在一个带虚拟内存的系统中， CPU 从一个有 N=2<sup>n</sup>个地址的地址空 间中生成虚拟地址，这个地址空间称为虚拟地址空间 (virtual address space): {0,1,2, …, N -1}

一个地址空间的大小是由表示最大地址所需要的位数来描述的。例如，一个包含 N= 2<sup>n</sup>个地址的虚拟地址空间就叫做一个 n 位地址空 间 。 现代系统通常支持 32 位或者 64 位虚拟地址空间。


## 物理地址空间
和虚拟空间类似，物理地址空间 (physical address space) , 对应于系统中物理内存的M个字节：{0,1,2, … ,M -1} 但M不要求是2的幂

# 虚拟内存作为缓存的工具
概念上而言，虚拟内存被组织为一个由存放在磁盘上的 N 个连续的字节大小的单元组成的数组 。 每字节都有一个唯一的虚拟地址，作为到数组的索引。磁盘上数组的内容被缓存在主存中 。 

和存储器层次结构中其他缓存一样，磁盘（较低层）上的数据被分割成块，这些块作为磁盘和主存（较高层）之间的传输单元 。

VM 系统通过将虚拟内存分割为称为虚拟页 (Virtual Page, VP) 的大小固定的块来处理这个问题 。 每个虚拟页的大小为 P= 2<sup>p</sup>字节 。 类似地，物理内存被分割为物理页 (Physical Page, PP) , 大小也为 P 字节（物理页也被称为页帧 (page frame )) 。

在任意时刻，虚拟页面的集合都分为三个不相交的子集：
-  未分配的： VM 系统还未分配（或者创建）的页 。 未分配的块没有任何数据和它们相关联，因此也就不占用任何磁盘空间。
- 缓存的：当前已缓存在物理内存中的已分配页 。
- 未缓存的：未缓存在物理内存中的已分配页 。

图 9 -3 的示例展示了一个有 8 个虚拟页的小虚拟内存。虚拟页 0 和 3 还没有被分配，因此在磁盘上还不存在。虚拟页 1、 4 和 6 被缓存在物理内存中。页 2 、 5 和 7 已经被分配了，但是当前并未缓存在主存中 。

![[eDqKLfGvNLCndwWt-86b331b0-612e-a67e-1339-478a1f0bf52b.png|542]]

## DRAM缓存组织结构
为了有助于清晰理解存储层次结构中不同的缓存概念，我们将使用术语 SRAM 缓存来表示位于 CPU 和主存之间的 L1 、 L2 和 L3 高速缓存，并且用术语 DRAM 缓存来表示虚拟内存系统的缓存，它在主存中缓存虚拟页 。

### DRAM巨大缓存开销
在存储层次结构中， DRAM 缓存的位置对它的组织结构有很大的影响。DRAM 比 SRAM 要慢大约 10 倍，而磁盘要比 DRAM 慢大约 100 000 多倍 。 因此，DRAM 缓存中的不命中比起 SRAM 缓存中的不命中要昂贵得多，这是因为 DRAM 缓存不命中要由磁盘来服务，而 SRAM 缓存不命中通常是由基千 DRAM 的主存来服务的。

因为大的不命中处罚和访问第一个字节的开销，虚拟页往往很大，通常是 4KB~2MB。由于大的不命中处罚， DRAM 缓存是全相联的，即任何虚拟页都可以放置在任何的物理页中。不命中时的替换策略也很重要，因为替换错了虚拟页的处罚也非常之高 。 因此，与硬件对 SRAM 缓存相比，操作系统对 DRAM 缓存使用了更复杂精密的替换算法。因为对磁盘的访问时间很长， DRAM 缓存总是使用写回，而不是直写。

## 页表
同任何缓存一样，虚拟内存系统必须有某种方法来判定一个虚拟页是否缓存在 DRAM 中的某个地方 。 如果是，系统还必须确定这个虚拟页存放在哪个物理页中。如果不命中，系统必须判断这个虚拟页存放在磁盘的哪个位置，在物理内存中选择一个牺牲页，并将虚拟页从磁盘复制到 DRAM 中，替换这个牺牲页。

这些功能是由软硬件联合提供的，包括操作系统软件、 MMU( 内存管理单元）中的地址翻译硬件和一个存放在物理内存中叫做页表 (page table) 的数据结构，页表将虚拟页映射到物理页。每次地址翻译硬件将一个虚拟地址转换为物理地址时，都会读取页表 。 操作
系统负责维护页表的内容，以及在磁盘与 DRAM 之间来回传送页。

### 页表的基本组织结构
页表就是一个页表条目 (Page Table Entry,PTE) 的数组。虚拟地址空间中的每个页在页表中一个固定偏移量处都有一个 PTE 。 

假设每个 PTE 是由一个有效位 (valid bit) 和一个 n 位地址字段组成
的。有效位表明了该虚拟页当前是否被物理内存缓存在 DRAM 中。

如果设置了有效位，那么地址字段就表示 DRAM 中相应的物理页的起始位置，这个物理页中缓存了该虚拟页。如果没有设置有效位，那么一个空地址表示这个虚拟页还未被分配。否则，这个地址就指向该虚拟页在磁盘上的起始位置。

图 9-4 中的示例展示了一个有 8 个虚拟页和 4 个物理页的系统的页表。四个虚拟页 (VP 1 、 VP 2 、 VP 4 和 VP7) 当前被缓存在 DRAM 中。两个页(VP 0 和 VP 5)还未被分配，而剩下的页 (VP 3 和 VP 6) 已经被分配了，但是当前还未被缓存。因为 DRAM 缓存是全相联的，所以任意物理页都可以包含任意虚拟页。

![[eDqKLfGvNLCndwWt-fe9f2882-93e3-5841-133a-af8fc39ee40a.png|514]]


## 页命中
![[eDqKLfGvNLCndwWt-043266e9-7e95-2109-6e08-32f3df7e6af2.png|861]]

## 缺页
在虚拟内存的习惯说法中， DRAM 缓存不命中称为缺页 (page fault) 。地址翻译硬件从内存中读取 PTE 3, 从有效位推断出 VP 3 未被缓存，并且触发一个缺页异常。

缺页异常调用内核中的缺页异常处理程序，该程序会选择一个牺牲页，在此例中就是存放在 pp 3 中的 VP 4 。如果 VP 4 已经被修改了，那么内核就会将它复制回磁盘。无论哪种情况，内核都会修改 VP4 的页表条目，反映出 VP 4 不再缓存在主存中这一事实。

![[eDqKLfGvNLCndwWt-77b25d5a-b20b-0ac3-6789-1935af1c12ea.png|609]]

接下来，内核从磁盘复制 VP 3 到内存中的 pp 3, 更新 PTE 3, 随后返回。当异常处理程序返回时，它会重新启动导致缺页的指令，该指令会把导致缺页的虚拟地址重发送到地址翻译硬件。但是现在， VP 3 已经缓存在主存中了，那么页命中也能由地址翻译硬件正常处理了。

![[eDqKLfGvNLCndwWt-94462d41-0529-8d41-f621-8d237b9f78df.png|827]]

## 虚拟内存缓存和SRAM缓存的不同术语
虚拟内存系统使用了和 SRAM 缓存不同的术语，即使它们的许多概念是相似的。

在虚拟内存的习惯说法中，块被称为页。在磁盘和内存之间传送页的活动叫做交换(swapping)或者页面调度(paging) 。页从磁盘换入（或者页面调入）DRAM 和从DRAM 换出（或者页面调出）磁盘。一直等待，直到最后时刻，也就是当有不命中发生时，才换入页面的这种策略称为按需页面调度(demand paging) 。也可以采用其他的方法，例如尝试着预测不命中，在页面实际被引用之前就换入页面。然而，所有现代系统都使用的是按需页面调度的方式。

## 分配页面(堆创建)
图 9-8 展示了当操作系统分配一个新的虚拟内存页时对我们示例页表的影响，例如，调用 malloc 的结果。在这个示例中， VP5 的分配过程是在磁盘上创建空间并更新 PTE 5, 使它指向磁盘上这个新创建的页面。

![[eDqKLfGvNLCndwWt-8547c084-ec96-f4a9-8d09-b5536daaf18b.png|503]]

## 局部性在虚拟内存缓存的作用
[[存储器的层次结构#局部性|局部性]]
尽管在整个运行过程中程序引用的不同页面的总数可能超出物理内存总的大小，但是局部性原则保证了在任意时刻，程序将趋向于在一个较小的活动页面 (active page)集合上工作，这个集合叫做工作集(working set)或者常驻集合(resident set) 。

在初始开销，也就是将工作集页面调度到内存中之后，接下来对这个工作集的引用将导致命中，而不会产生额外的磁盘流量。

只要我们的程序有好的时间局部性，虚拟内存系统就能工作得相当好。但是，当然不是所有的程序都能展现良好的时间局部性。如果工作集的大小超出了物理内存的大小，那么程序将产生一种不幸的状态，叫做抖动 (thrashing), 这时页面将不断地换进换出程序性能就会慢得像爬一样。

# 虚拟内存作为内存管理的工具
到目前为止，我们都假设有一个单独的页表，将一个虚拟地址空间映射到物理地址空间。实际上，操作系统为每个进程提供了一个独立的页表，因而也就是一个独立的虚拟地址空间。

图 9-9展示了基本思想。在这个示例中，进程i 的页表将 V P1 映射到 PP 2, VP 2 映射到 PP 7。相似地，进程j 的页表将V P1 映射到PP 7，VP 2 映射到 PP 10 。 注意，多个虚拟页面可以映射到同一个共享物理页面上。

![[eDqKLfGvNLCndwWt-66241fbb-5c5c-de47-da94-589928e8a3cb.png|466]]


按需页面调度和独立的虚拟地址空间的结合，对系统中内存的使用和管理造成了深远的影响 。特别地， VM 简化了链接和加载、代码和数据共享，以及应用程序的内存分配

## 简化链接
独立的地址空间允许每个进程的内存映像使用相同的基本格式，而不管代码和数据实际存放在物理内存的何处 。对于 64 位地址空间，代码段总是从虚拟地址 0x400000 开始。数据段跟在代码段之后，中间有一段符合要求的对齐空白 。 栈占据用户进程地址空间最高的部分，并向下生长。这样的一致性极大地简化了链接器的设计和实现，允许链接器生成完全链接的可执行文件，这些可执行文件是独立于物理内存中代码和数据的最终位置的 。

## 简化加载
虚拟内存还使得容易向内存中加载可执行文件和共享对象文件 。 要把目标文件中 .text 和 . data 节加载到一个新创建的进程中， Linux 加载器为代码和数据段分配虚拟页，把它们标记为无效的（即未被缓存的），将页表条目指向目标文件中适当的位置 。

有趣的是，加载器从不从磁盘到内存实际复制任何数据。在每个页
初次被引用时，要么是 CPU 取指令时引用的，要么是一条正在执行的指令引用一个内存位置时引用的，虚拟内存系统会按照需要自动地调入数据页。

将一组连续的虚拟页映射到任意一个文件中的任意位置的表示法称作内存映射 (mem­ory mapping) 。
## 简化共享
独立地址空间为操作系统提供了一个管理用户进程和操作系统自身之间共享的一致机制 。 一般而言，每个进程都有自己私有的代码、数据、堆以及栈区域，是不和其他进程共享的 。 在这种情况中，操作系统创建页表，将相应的虚拟页映射到不连续的物理页面 。

然而，在一些情况中，还是需要进程来共享代码和数据 。 例如，每个进程必须调用相同的操作系统内核代码，而每个 C 程序都会调用 C 标准库中的程序，比如 printf。操作系统通过将不同进程中适当的虚拟页面映射到相同的物理页面，从而安排多个进程共享这部分代码的一个副本，而不是在每个进程中都包括单独的内核和 C 标准库的副本
## 简化内存分配
虚拟内存为向用户进程提供一个简单的分配额外内存的机制。当一个运行在用户进程中的程序要求额外的堆空间时（如调用 malloc 的结果），操作系统分配一个适当数字（例如 k)个连续的虚拟内存页面，并且将它们映射到物理内存中任意位置的 K 个任意的物理页面。由于页表工作的方式，操作系统没有必要分配k 个连续的物理内存页面。页面可以随机地分散在物理内存中。

# 虚拟内存作为内存保护的工具
任何现代计算机系统必须为操作系统提供手段来控制对内存系统的访问。不应该允许一个用户进程修改它的只读代码段。而且也不应该允许它读或修改任何内核中的代码和数据结构。不应该允许它读或者写其他进程的私有内存，并且不允许它修改任何与其他进程共享的虚拟页面，除非所有的共享者都显式地允许它这么做（通过调用明确的进程间通信系统调用）。

提供独立的地址空间使得区分不同进程的私有内存变得容易。但是，地址翻译机制可以以一种自然的方式扩展到提供更好的访问控制。因为每次 CPU 生成一个地址时，地址翻译硬件都会读一个 PTE, 所以通过在 PTE 上添加一些额外的许可
位来控制对一个虚拟页面内容的访问十分简单。图 9-10 展示了大致的思想。

![[eDqKLfGvNLCndwWt-842fdd43-04b1-beba-6a48-0dc37ef860ac.png|671]]

在这个示例中，每个 PTE 中已经添加了三个许可位。 SUP 位表示进程是否必须运行在内核（超级用户）模式下才能访问该页。运行在内核模式中的进程可以访问任何页面，但是运行在用户模式中的进程只允许访问那些 SUP 为 0 的页面。 READ 位和 WRITE 位控制对页面的读和写访问。

例如，如果进程 i 运行在用户模式下，那么它有读 VP 0 和读写VP 1 的权限。然而，不允许它访问 VP 2 。

如果一条指令违反了这些许可条件，那么 CPU 就触发一个一般保护故障，将控制传递给一个内核中的异常处理程序。 Linux shell 一般将这种异常报告为＂段错误 (segmenta­tion fault)" 。

# 地址翻译(核心)
## 地址翻译简要原理
![[eDqKLfGvNLCndwWt-44215a0d-ad95-12b4-08a5-e5549173932e.png|574]]

1. VPN（Virtual Page Number，虚拟页号）：在虚拟内存系统中，VPN通常用于标识虚拟地址中的页号部分。在给定一个32位的虚拟地址空间时，如果使用标准的4KB页面大小（即2的12次方个字节），则虚拟页号的位数可以计算为：32 - log2(页大小)，即32 - 12 = 20位。
    
2. VPO（Virtual Page Offset，虚拟页偏移）：VPO用于表示虚拟地址中与页面大小相关的偏移部分。对于4KB的页面大小，偏移的位数等于页面大小的对数，即12位。
    
3. PPN（Physical Page Number，物理页号）：在虚拟内存系统中，PPN用于标识物理地址中的页号部分。由于给定了24位的物理地址空间，物理页号的位数等于物理地址空间大小与页面大小的对数，即24 - log2(页大小) = 24 - 12 = 12位。
    
4. PPO（Physical Page Offset，物理页偏移）：与VPO类似，PPO表示物理地址中与页面大小相关的偏移部分。对于4KB的页面大小，PPO的位数也是12位。

形式上来说，地址翻译是一个 N 元素的虚拟地址空间 (VAS) 中的元素和一个 M 元素的物理地址空间 (PAS) 中元素之间的映射，
## MMU地址控制器
图 9- 12 展示了 MMU 如何利用页表来实现这种映射 。 CPU 中的一个控制寄存器，页表基址寄存器(Page Table Base Register, PTBR)指向 当前页表。n 位的虚拟地址包含两个部分：一个 p 位的虚拟页面偏移 (Virtual Page Offset, VPO) 和一个 (n — p) 位的虚拟页号 (VirtualPage Number, VPN) 。 MMU 利用 VPN 来选择适当的 PTE。

例如， VPN 0 选择 PTE 0,VPN 1 选择 PTE 1, 以此类推。将页表条目中物理页号 (Physical Page Number, PPN)和虚拟地址中的 VPO 串联起来，就得到相应的物理地址。注意，因为物理和虚拟页面都是 P 字节的，所以物理页面偏移 (Physical Page Off set, PPO) 和 VPO 是相同的 。

![[eDqKLfGvNLCndwWt-ad0bd52a-16a5-ad90-20ef-f71173970904.png|724]]


图 9-13a 展示了当页面命中时， CPU 硬件执行的步骤。
- 笫 1 步 ： 处理器生成一个虚拟地址，并把它传送给 MMU 。
- 笫 2 步： MMU 生成 PTE 地址，并从高速缓存／主存请求得到它 。 
- 笫 3 步：高速缓存／主存向 MMU 返回 PTE 。
- 笫 4 步： MMU 构造物理地址，并把它传送给高速缓存／主存 。
- 笫 5 步：高速缓存／主存返回所请求的数据字给处理器 。
- 
页面命中完全是由硬件来处理的，与之不同的是，处理缺页要求硬件和操作系统内核协作完成，如图 9-13b 所示。

- 笫 1 步到笫 3 步 ： 和图 9- 13a 中的第 1 步到第 3 步相同 。
- 第 4 步： PTE 中的有效位是零 ，所以 MMU 触发了一次异常，传递 CPU 中的控制到操作系统内核中的缺页异常处理程序。
- 笫 5 步 ： 缺页处理程序确定出物理内存中的牺牲页，如果这个页面已经修改了，则把它换出到磁盘。
- 笫 6 步 ： 缺页处理程序页面调入新的页面，并更新内存中的 PTE 。
- 第 7 步：缺页处理程序返回到原来的进程，再次执行导致缺页的指令。 CPU 将引起缺页的虚拟地址重新发送给 MMU。因为虚拟页面现在缓存在物理内存中，所以就会命中，在 MMU 执行了图 9-13b 中的步骤之后，主存就会将所请求字返回给处理器 。
![[eDqKLfGvNLCndwWt-5cdac951-14f5-c1a7-67e9-3f3af32defcf.png|740]]

## 结合高速缓存和虚拟内存(多次PTE)
TLB（Translation Lookaside Buffer）存储了从虚拟地址直接映射到物理地址的信息。TLB 是一种高速缓存，用于存储最近使用的虚拟地址到物理地址的转换结果，以提高地址转换的速度。

在任何既使用虚拟内存又使用 SRAM 高速缓存的系统中，都有应该使用虚拟地址还是使用物理地址来访问 SRAM 高速缓存的问题。大多数系统是选择物理寻址的。使用物理寻址，多个进程同时在高速缓存中有存储块和共享来自相同虚拟页面的块成为很简单的事情 。 而且，高速缓存无需处理保护问题，因为访问权限的检查是地址翻译过程的一部分 。

图 9-14 展示了一个物理寻址的高速缓存如何和虚拟内存结合起来 。 主要的思路是地址翻译发生在高速缓存查找之前 。 注意，页表条目可以缓存，就像其他的数据字一样。

![[eDqKLfGvNLCndwWt-788e967e-d8d2-cd44-2b86-7b1f5bebcead.png|675]]

## 利用 TLB 加速地址翻译
正如我们看到的，每次 CPU 产生一个虚拟地址， MMU 就必须查阅一个 PTE, 以便将虚拟地址翻译为物理地址。在最糟糕的情况下，这会要求从内存多取一次数据，代价是几十到几百个周期。如果 PTE 碰巧缓存在 L1 中，那么开销就下降到 1 个或 2 个周期。然而，许多系统都试图消除即使是这样的开销，它们在 MMU 中包括了一个关于 PTE 的小的缓存，称为翻译后备缓冲器 (Translation Lookaside Buffer, TLB) 。

TLB 是一个小的、虚拟寻址的缓存，其中每一行都保存着一个由单个 PTE 组成的块。TLB 通常有高度的相联度。如图 9-15 所示，用于组选择和行匹配的索引和标记字段是从虚拟地址中的虚拟页号中提取出来的。如果 TLB 有 T=2<sup>t</sup> 个组，那么 TLB 索引 (TLBD)是由 VPN 的 t 个最低位组成的，而 TLB 标记(TLBT)是由 VPN 中剩余的位组成的。


![[eDqKLfGvNLCndwWt-172cacbc-773e-f8c5-d024-86f23b557dfa.png|411]]


图 9-16a 展示了当 TLB 命中时（通常情况）所包括的步骤。这里的关键点是，所有的地址翻译步骤都是在芯片上的 MMU 中执行的，因此非常快。

- 笫 1 步： CPU 产生一个虚拟地址。
- 第 2 步和笫 3 步： MMU 从 TLB 中取出相应的 PTE 。
- 第 4 步： MMU 将这个虚拟地址翻译成一个物理地址，并且将它发送到高速缓存／主存。
- 第 5 步：高速缓存／主存将所请求的数据字返回给 CPU 。

当 TLB 不命中时， MMU 必须从 L1 缓存中取出相应的 PTE, 如图 9- 16b 所示。新取出的 PTE 存放在 TLB 中，可能会覆盖一个已经存在的条目。

![[eDqKLfGvNLCndwWt-5532ebf2-cac3-9d3a-038b-3d726d92e0ee.png|872]]

## 多级页表
到目前为止，我们一直假设系统只用一个单独的页表来进行地址翻译。但是如果我们有一个 32 位的地址空间、 4KB 的页面和一个 4 字节的 PTE, 那么即使应用所引用的只是虚拟地址空间中很小的一部分，也总是需要一个 4MB 的页表驻留在内存中。对于地址空间为 64 位的系统来说，问题将变得更复杂。

用来压缩页表的常用方法是使用层次结构的页表 。假设 32 位虚拟地址空间被分为 4KB 的页，而每个页表条目都是 4 字节。还假设在这一时刻，虚拟地址空间有如下形式：内存的前 2K 个页面分配给了代码和数据，接下来的 6K 个页面还未分配，再接下来的 1023 个页面也未分配，接下来的 1 个页面分配给了用户栈。图 9- 17 展示了我们如何为这个虚拟地址空间构造一个两级的页表层次结构。

![[eDqKLfGvNLCndwWt-e1105ca7-72b6-ca75-99b6-95a737c11653.png|769]]

一级页表中的每个 PTE 负责映射虚拟地址空间中一个 4MB 的片 (chunk), 这里每一片都是由 1024 个连续的页面组成的。比如， PTE 0 映射第一片， PTE 1 映射接下来的一片，以此类推。假设地址空间是 4GB, 1024 个 PTE 已经足够覆盖整个空间了。

如果片 1 中的每个页面都未被分配，那么一级 PTEi 就为空 。 例如，图 9- 17 中，片 2~7是未被分配的。然而，如果在片 t 中至少有一个页是分配了的，那么一级 PTE i 就指向一个二级页表的基址。例如，在图 9-17 中，片 0 、 1 和 8 的所有或者部分已被分配，所以它们的一级 PTE 就指向二级页表。

二级页表中的每个 PTE 都负责映射一个 4KB 的虚拟内存页面，就像我们查看只有一级的页表一样。注意，使用 4 字节的 PTE, 每个一级和二级页表都是 4KB 字节，这刚好和一个页面的大小是一样的

这种方法从两个方面减少了内存要求。第一 ，如果一级页表中的一个 PTE 是空的，那么相应的二级页表就根本不会存在 。 这代表着一种巨大的潜在节约，因为对于一个典型的程序， 4GB 的虚拟地址空间的大部分都会是未分配的。

第二，只有一级页表才需要总是在主存中；虚拟内存系统可以在需要时创建、页面调入或调出二级页表，这就减少了主存的压力；只有最经常使用的二级页表才需要缓存在主存中 。



图 9-18 描述了使用 K 级页表层次结构的地址翻译。虚拟地址被划分成为 K 个 VPN 和1 个 VPO 。 每个 VPN i 都是一个到第 i 级页表的索引，其中 1 <= i <=k。第 1 级页表中的每个 PTE, 1 <=j <=k-1, 都指向第 j + 1 级的某个页表的基址。第 K 级页表中的每个 PTE 包含某个物理页面的 PPN, 或者一个磁盘块的地址。为了构造物理地址 ， 在能够确定 PPN之前， MMU 必须访问 K 个 PTE。对于只有一级的页表结构， PPO 和 VPO 是相同的。

![[eDqKLfGvNLCndwWt-8dd1adb5-7fab-cfa2-0a28-5981a2d87024.png|527]]

访问 k 个 PTE, 第一眼看上去昂贵而不切实际。然而，这里 TLB 能够起作用，正是通过将不同层次上页表的 PTE 缓存起来。实际上，带多级页表的地址翻译并不比单级页表慢很多。

## 实验:端到端地址翻译
[综合：端到端的地址翻译](obsidian://bookmaster?type=open-book&bid=eDqKLfGvNLCndwWt&aid=1b4df92d-5348-f59c-f6d2-7c5a8c563702&page=609)

# 案例探究:Intel Core i7 /Linux 内存系统
我们以一个实际系统的案例研究来总结我们对虚拟内存的讨论：一个运行 Linux 的Intel Core i7 。现在的（以及可预见的未来的）Core i7 实现支持 48 位(256TB) 虚拟地址空间和 52 位 (4PB)物理地址空间，还有一个兼容模式，支持 32 位 (4GB)虚拟和物理地址空间。

图 9-21 给出了 Core i7 内存系统的重要部分。处理器封装(processor package) 包括四个核、一个大的所有核共享的 L3 高速缓存，以及一个 DDR3 内存控制器。每个核包含一个层次结构的 TLB、一个层次结构的数据和指令高速缓存，以及一组快速的点到点链路

这种链路基于 QuickPath 技术，是为了让一个核与其他核和外部 I/O 桥直接通信。 TLB是虚拟寻址的，是四路组相联的 。 L1 、 L2 和 L3 高速缓存是物理寻址的，块大小为 64 字节。 Ll 和 LZ 是 8 路组相联的，而 L3 是 16 路组相联的。页大小可以在启动时被配置为4KB 或 4MB 。 Linux 使用的是 4KB 的页。

![[eDqKLfGvNLCndwWt-ddcfe2b1-2f41-b2b9-f7a7-4d1291cca704.png|835]]


## Core i7地址翻译
### 翻译过程
图 9-22 总结了完整的 Core i7 地址翻译过程，从 CPU 产生虚拟地址的时刻一直到来自内存的数据字到达 CPU 。

Core i7 采用四级页表层次结构。每个进程有它自己私有的页表层次结构。当一个 Linux 进程在运行时，虽然 Core i7 体系结构允许页表换进换出，但是与已分配了的页相关联的页表都是驻留在内存中的。

CR3 控制寄存器指向第一级页表(L1) 的起始位置。 CR3 的值是每个进程上下文的一部分，每次上下文切换时， CR3 的值都会被恢复。

![[eDqKLfGvNLCndwWt-af720068-f3c6-deb3-2cab-bd2fa22dc4f4.png|800]]

### 不同层级的页表条目(PTE结构剖析)
图 9-23 给出了第一级、第二级或第三级页表中条目(PTE)的格式 。 当 P= 1 时 (Linux 中就总是如此），地址字段包含一个 40 位物理页号 (PPN), 它指向适当的页表的开始处。注意，这强加了一个要求，要求物理页表 4KB 对齐。

![[eDqKLfGvNLCndwWt-9330a423-b6bf-d8f4-3cd7-8ca18759bace.png|730]]

图 9-24 给出了第四级页表中条目的格式。当 P=l, 地址字段包括一个 40 位 PPN,
它指向物理内存中某一页的基地址。这又强加了一个要求，要求物理页 4KB 对齐。

![[eDqKLfGvNLCndwWt-15eb4795-3764-29ca-1528-6b45bc6bb11b.png|856]]

PTE 有三个权限位，控制对页的访问。 R/W 位确定页的内容是可以读写的还是只读的。U/S 位确定是否能够在用户模式中访问该页，从而保护操作系统内核中的代码和数据不被用户程序访问。 XD(禁止执行）位是在 64 位系统中引入的，可以用来禁止从某些内存页取指令。这是一个重要的新特性，通过限制只能执行只读代码段，使得操作系统内核降低了缓冲区溢出攻击的风险。

### MMU修改PTE
当 MMU 翻译每一个虚拟地址时，它还会更新另外两个内核缺页处理程序会用到的位 。 每次访问一个页时， MMU 都会设置 A 位，称为引用位 (reference bit) 。

内核可以用这个引用位来实现它的页替换算法。每次对一个页进行了写之后， MMU 都会设置 D 位，又称修改位或脏位(dirty bit）。修改位告诉内核在复制替换页之前是否必须写回牺牲页。内核可以通过调用一条特殊的内核模式指令来清除引用位或修改位 。

### 如何使用四级页表翻译成物理地址
图 9-25 给出了 Core i7 MMU 如何使用四级的页表来将虚拟地址翻译成物理地址。 36位 VPN 被划分成四个 9 位的片，每个片被用作到一个页表的偏移量。 CR3 寄存器包含 L1页表的物理地址。 VPN 1 提供到一个 L1 PET 的偏移量 ，这个 PTE 包含 L2 页表的基地址。 VPN 2 提供到一个 L2 PTE 的偏移量，以此类推。

![[eDqKLfGvNLCndwWt-84fb245c-5a6f-3ccd-82f2-332e64533a9d.png|843]]

### 优化地址翻译
在对地址翻译的讨论中，我们描述了一个顺序的两个步骤的过程， l)MMU 将虚拟地址翻译成物理地址， 2)将物理地址传送到 L1 高速缓存 。 然 而 ， 实际的硬件实现使用了一个灵活的技巧，允许这些步骤部分重叠 ， 因此也就加速了对 L1 高速缓存的访问。

例如，页面大小为 4KB 的 Core i7 系统上的一个虚拟地址有 12 位的 VPO, 并且这些位和相应物理地址中的 PPO 的 12 位是相同的 。 因为八路组相联的、物理寻址的 L1 高速缓存有 64 个组和大小为 64 宇节的缓存块 ， 每个物理地址有 6 个 (log2 64) 缓存偏移位和6 个(log2 64) 索引位 。 这 12 位恰好符合虚拟地址的 VPO 部分

当 CPU需要翻译一个虚拟地址时，它就发送 VPN 到 MMU, 发送 VPO 到高速 L1缓存 。 当 MMU向 TLB 请求一个页表条目时， L1 高速缓存正忙着利用 VPO 位查找相应的组，并读出这个组里的 8 个标记和相应的数据宇 。 当 MMU 从 TLB 得到 PPN 时，缓存已经准备好试着把这个 PPN 与这 8 个标记中的一个进行匹配了 。

## Linux虚拟内存系统
Linux 为每个进程维护了一个单独的虚拟地址空间，形式如图 9-26 所示 。
![[eDqKLfGvNLCndwWt-7fd3fb43-70a1-48f1-d40e-9d32535b2e07.png|423]]

内核虚拟内存包含内核中的代码和数据结构 。 内核虚拟内存的某些区域被映射
到所有进程共享的物理页面。例如，每个进程共享内核的代码和全局数据结构。有趣的是， Linux 也将一组连续的虚拟页面（大小等于系统中 DRAM 的总量）映射到相应的一组连续的物理页面 。这就为内核提供了一种便利的方法来访问物理内存中任何特定的位置，例如，当它需要访问页表，或在一些设备上执行内存映射的 I/O操作，而这些设备被映射到特定的可用物理内存位置时。

内核虚拟内存的其他区域包含每个进程都不相同的数据 。 比如说，页表、内核在进程的上下文中执行代码时使用的栈，以及记录虚拟地址空间当前组织的各种数据结构 。

### Linux虚拟内存区域
#### area(区域)
Linux 将虚拟内存组织成一些区域（也叫做段）的集合 。 一个区域 (area) 就是已经存在着的（已分配的）虚拟内存的连续片 (chunk), 这些页是以某种方式相关联的。例如，代码段、数据段、堆、共享库段，以及用户栈都是不同的区域。

每个存在的虚拟页面都保存在某个区域中，而不属于某个区域的虚拟页是不存在的，并且不能被进程引用 。 区域的概念很重要，因为它允许虚拟地址空间有间隙。内核不用记录那些不存在的虚拟页，而这样的页也不占用内存、磁盘或者内核本身中的任何额外资源 。

#### 描述虚拟内存区域的数据结构
图 9-27 强调了记录一个进程中虚拟内存区域的内核数据结构。内核为系统中的每个进程维护一个单独的任务结构（源代码中的 task_struct) 。任务结构中的元素包含或者指向内核运行该进程所需要的所有信息（例如， PID、指向用户栈的指针、可执行目标文件的名字，以及程序计数器） 。
![[eDqKLfGvNLCndwWt-b807fcf8-6c9c-f8ad-8f3d-08d0aca345fc.png|715]]

任务结构中的一个条目指向 mm_struct, 它描述了虚拟内存的当前状态 。 我们感兴趣的两个字段是 pgd 和 mmap, 其中 pgd 指向第一级页表（页全局目录）的基址，而 mmap 指向一个vm_area_structs(区域结构）的链表，其中每个 vm_area_structs 都描述了当前虚拟地址空间的一个区域。当内核运行这个进程时，就将 pgd 存放在 CR3 控制寄存器中 。

为了我们的目的，一个具体区域的区域结构包含下面的字段：
- vm_start: 指向这个区域的起始处 。
- vm_end: 指向这个区域的结束处 。
- vm_prot: 描述这个区域内包含的所有页的读写许可权限。
- vm_flags: 描述这个区域内的页面是与其他进程共享的，还是这个进程私有的（还描述了其他一些信息） 。
- vm_next: 指向链表中下一个区域结构。

### Linux缺页异常处理
假设 MMU 在试图翻译某个虚拟地址 A 时，触发了一个缺页 。 这个异常导致控制转移到内核的缺页处理程序，处理程序随后就执行下面的步骤：
![[eDqKLfGvNLCndwWt-819381b1-640a-94cb-8267-3b886ed1685a.png|604]]

#### 虚拟地址 A 是合法的吗？
换句话说， A 在某个区域结构定义的区域内吗？为了回答这个问题，缺页处理程序搜索区域结构的链表，把 A 和每个区域结构中的 vm_start 和vm_end 做比较。如果这个指令是不合法的，那么缺页处理程序就触发一个段错误，从而终止这个进程。这个情况在图 9-28 中标识为 "1" 。

具体来说，缺页处理程序会按照以下步骤进行：
1. 遍历区域结构链表，检查每个区域结构的 `vm_start` 和 `vm_end`。
2. 对于每个区域结构，判断虚拟地址 A 是否在其定义的区域内，即检查 A 是否满足 `vm_start <= A < vm_end` 的条件。
3. 如果 A 符合某个区域结构的范围，则认为 A 是合法的虚拟地址，进而执行相应的操作（例如，进行页面加载或其他处理）。
4. 如果 A 未匹配任何区域结构的范围，则认为 A 是非法的虚拟地址，可能触发缺页异常或其他错误处理。

#### 试图进行的内存访问是否合法？(缺页处理程序)
换句话说，进程是否有读、写或者执行这个区域内页面的权限？例如，这个缺页是不是由一条试图对这个代码段里的只读页面进行写操作的存储指令造成的？这个缺页是不是因为一个运行在用户模式中的进程试图从内核虚拟内存中读取字造成的？如果试图进行的访问是不合法的，那么缺页处理程序会触发一个保护异常，从而终止这个进程。这种情况在图 9-28 中标识为 "2" 。

当程序试图访问一个虚拟内存地址，但该地址对应的页面尚未被加载到物理内存中时，就会触发缺页异常。
1. 首先，缺页处理程序会检查进程是否有对该区域内页面的读、写或执行权限。这涉及到区域结构中定义的页面权限信息，例如，一个代码段可能只允许执行权限，而一个数据段可能允许读和写权限。
    
2. 接下来，程序会检查试图进行的内存访问是否符合区域的权限。例如，如果一个只读页面被试图写入，或者一个没有执行权限的区域被试图执行，这样的访问是不合法的。
    
3. 进一步地，程序会考虑访问是否跨越了用户模式和内核模式之间的边界。如果一个运行在用户模式中的进程试图访问内核虚拟内存，或者试图执行内核态代码，这样的访问也是不合法的。
    
4. 如果试图进行的访问是不合法的，缺页处理程序会触发一个保护异常，这将导致操作系统中断当前进程的执行，并根据异常类型执行相应的错误处理流程，可能包括终止进程等操作。

总的来说，缺页异常的触发是因为页面尚未加载到物理内存中，而处理缺页异常则需要通过访问磁盘空间来获取缺失页面的数据，并将其加载到内存中。而访问磁盘空间常常涉及到读写，执行等权限操作，所以才需要缺页异常程序进行处理，并将内容从磁盘复制到内存

#### 合法的处理
此刻，内核知道了这个缺页是由于对合法的虚拟地址进行合法的操作造成的。它是这样来处理这个缺页的：选择一个牺牲页面，如果这个牺牲页面被修改过，那么就将它交换出去，换入新的页面并更新页表 。 当缺页处理程序返回时， CPU 重新启动引起缺页的指令，这条指令将再次发送 A 到 MMU。这次， MMU 就能正常地翻译 A, 而不会再产生缺页中断了 。

# 内存映射
Linux 通过将一个虚拟内存区域与一个磁盘上的对象 (object) 关联起来，以初始化这个虚拟内存区域的内容，这个过程称为内存映射(memory mapping) 。虚拟内存区域可以映射到两种类型的对象中的一种：

1) Linux 文件系统中的普通文件
	1. **普通文件区域映射到磁盘文件的连续部分**：普通文件在磁盘上的存储是连续的，例如一个可执行目标文件会在磁盘上占据一段连续的空间。
    
	2. **文件区分成页大小的片**：文件区域被划分成大小为页大小的片段，这些片段包含了虚拟页面的初始内容。这里的“页大小”指的是操作系统所使用的页面大小，通常是 4KB 或者 4MB。
    
	3. **虚拟页面的按需调度**：在 Linux 系统中，虚拟内存管理采用了按需调度的策略，意味着虚拟页面在被 CPU 首次引用之前并不会被实际交换到物理内存中，而是等待 CPU 首次访问。
    
	4. **如果区域比文件区要大**：如果文件区域比文件本身要大，例如文件的大小没有填满整个区域，那么剩余的部分会被用零来填充。
2) 匿名文件：一个区域也可以映射到一个匿名文件，匿名文件是由内核创建的，包含的全是二进制零。 CPU 第一次引用这样一个区域内的虚拟页面时，内核就在物理内存中找到一个合适的牺牲页面，如果该页面被修改过，就将这个页面换出来，用二进制零覆盖牺牲页面并更新页表，将这个页面标记为是驻留在内存中的。注意在磁盘和内存之间并没有实际的数据传送。因为这个原因，映射到匿名文件的区域中的页面有时也叫做请求二进制零的页 (demand-zero page) 。

无论在哪种情况中，一旦一个虚拟页面被初始化了，它就在一个由内核维护的专门的交换文件(swap file)之间换来换去 。 交换文件也叫做交换空间 (swap space) 或者交换区域(swap area) 。需要意识到的很重要的一点是，在任何时刻，交换空间都限制着当前运行着的进程能够分配的虚拟页面的总数。

## 再看共享对象
内存映射的概念来源于一个聪明的发现：如果虚拟内存系统可以集成到传统的文件系统中，那么就能提供一种简单而高效的把程序和数据加载到内存中的方法。

正如我们已经看到的，进程这一抽象能够为每个进程提供自己私有的虚拟地址空间，可以免受其他进程的错误读写。不过，许多进程有同样的只读代码区域。例如，每个运行Linux shell 程序 bash 的进程都有相同的代码区域。而且，许多程序需要访问只读运行时库代码的相同副本。例如，每个 C 程序都需要来自标准 C 库的诸如 printf 这样的函数。

那么，如果每个进程都在物理内存中保持这些常用代码的副本，那就是极端的浪费了。幸运的是，内存映射给我们提供了一种清晰的机制，用来控制多个进程如何共享对象。

### 共享对象和私有对象
一个对象可以被映射到虚拟内存的一个区域，要么作为共享对象，要么作为私有对象。实际上也就是在页表中添加磁盘对象的PTE信息，从而在虚拟空间建立了映射关系。如果一个进程将一个共享对象映射到它的虚拟地址空间的一个区域内，那么这个进程对这个区域的任何写操作，对于那些也把这个共享对象映射到它们虚拟内存的其他进程而言，也是可见的。而且，这些变化也会反映在磁盘上的原始对象中。

另一方面，对于一个映射到私有对象的区域做的改变，对于其他进程来说是不可见的，并且进程对这个区域所做的任何写操作都不会反映在磁盘上的对象中。一个映射到共享对象的虚拟内存区域叫做共享区域。类似地，也有私有区域。

"对象"指的是在操作系统中表示的一块内存区域，通常是指文件或者进程间通信的共享内存区域。它与编程语言中的类对象有些不同，更类似于操作系统层面的概念，用于描述虚拟内存中的一块数据。

共享对象和私有对象是针对<font color="#ff0000">进程之间共享内存的不同使用方式</font>而言的，并不是指编程语言中的类中的公有和私有成员。在这里，共享对象表示多个进程可以将同一个对象映射到它们各自的虚拟内存空间中，这样它们就可以共享对这个对象的访问和修改。而私有对象则只能被单个进程所访问和修改，其他进程无法直接访问这个对象。

假设进程 1 将一个共享对象映射到它的虚拟内存的一个区域中，如图 9-29a 所示。现在假设进程 2 将同一个共享对象映射到它的地址空间（并不一定要和进程 1 在相同的虚拟地址处，如图 9-29b 所示）。

![[eDqKLfGvNLCndwWt-a5312c24-470d-ae2b-0d47-642926da2aab.png|765]]

因为每个对象都有一个唯一的文件名，内核可以迅速地判定进程 1 已经映射了这个对象，而且可以使进程 2 中的页表条目指向相应的物理页面。关键点在于即使对象被映射到了多个共享区域，物理内存中也只需要存放共享对象的一个副本。为了方便，我们将物理页面显示为连续的，但是在一般情况下当然不是这样的。


#### 写时复制(私有)
私有对象使用一种叫做写时复制 (copy-on-write) 的巧妙技术被映射到虚拟内存中。一个私有对象开始生命周期的方式基本上与共享对象的一样，在物理内存中只保存有私有对象的一份副本。

比如，图 9-30a 展示了一种情况，其中两个进程将一个私有对象映射到它们虚拟内存的不同区域，但是共享这个对象同一个物理副本。对于每个映射私有对象的进程，相应私有区域的页表条目都被标记为只读，并且区域结构被标记为私有的写时复制。只要没有进程试图写它自己的私有区域，它们就可以继续共享物理内存中对象的一个单独副本。然而，只要有一个进程试图写私有区域内的某个页面，那么这个写操作就会触发一个保护故障。

当故障处理程序注意到保护异常是由于进程试图写私有的写时复制区域中的一个页面而引起的，它就会在物理内存中创建这个页面的一个新副本，更新页表条目指向这个新的副本，然后恢复这个页面的可写权限，如图 9-30b 所示 。 当故障处理程序返回时， CPU 重新执行这个写操作，现在在新创建的页面上这个写操作就可以正常执行了 。

![[eDqKLfGvNLCndwWt-c7d973c1-688c-f4c3-fb6b-768a7e0dd0ff.png|839]]

通过延迟私有对象中的副本直到最后可能的时刻，写时复制最充分地使用了稀有的物理内存。

## 再看fork函数
既然我们理解了虚拟内存和内存映射，那么我们可以清晰地知道 fork 函数是如何创建一个带有自己独立虚拟地址空间的新进程的。

1. 当一个进程调用`fork()`函数创建一个新进程时，内核会为新进程创建各种数据结构，包括进程控制块（Process Control Block, PCB）等，并为新进程分配一个唯一的进程标识符（PID）。
    
2. 为了给新进程创建虚拟内存空间，内核会复制当前进程的内存管理数据结构，包括`mm_struct`（描述进程的内存布局）、区域结构（描述内存中不同区域的属性）、页表等。这些数据结构的副本会分配给新进程。
    
3. 为了确保新旧进程之间的内存空间相互独立，内核会将每个页面标记为只读，并将区域结构标记为私有的写时复制。这意味着，当一个进程试图写入一个被标记为只读的页面时，操作系统会产生一个异常，从而防止进程对相同内存空间的直接修改。而写时复制机制则确保了在实际需要写入数据时才会创建页面的副本，从而节约内存空间

当 fork 在新进程中返回时，新进程现在的虚拟内存刚好和调用 fork 时存在的虚拟内存相同 。 当这两个进程中的任一个后来进行写操作时，写时复制机制就会创建新页面，因此，也就为每个进程保持了私有地址空间的抽象概念。

## 再看 execve 函数
虚拟内存和内存映射在将程序加载到内存的过程中也扮演着关键的角色。既然已经理解了这些概念，我们就能够理解 execve 函数实际上是如何加载和执行程序的。假设运行在当前进程中的程序执行了如下的 execve 调用：
[[异常控制流#加载并运行程序(execve)|execve]]
- execve("a.out", NULL, NULL);


execve 函数在当前进程中加载并运行包含在可执行目标文件a.out中的程序，用 a.out 程序有效地替代了当前程序。加载并运行 a.out 需要以下几个步骤：
- 删除已存在的用户区域。删除当前进程虚拟地址的用户部分中的已存在的区域结构。
- 映射私有区域。为新程序的代码、数据、 bss 和栈区域创建新的区域结构。所有这些新的区域都是私有的、写时复制的。代码和数据区域被映射为 a.out 文件中的 .text和 .data 区。 bss 区域是请求二进制零的，映射到匿名文件，其大小包含在a.out中 。 栈和堆区域也是请求二进制零的，初始长度为零。图 9-31 概括了私有区域的不同映射。
- 映射共享区域。如果 a.out 程序与共享对象（或目标）链接，比如标准 C 库 libc.so, 那么这些对象都是动态链接到这个程序的，然后再映射到用户虚拟地址空间中的共享区域内。
- 设置程序计数器 (PC) 。 execve 做的最后一件事情就是设置当前进程上下文中的程序计数器，使之指向代码区域的入口点 。

下一次调度这个进程时，它将从这个入口点开始执行 。 Linux 将根据需要换入代码和
数据页面。

![[eDqKLfGvNLCndwWt-5b1a398a-f198-4731-de93-31122898167f.png|579]]

## mmap函数的用户级内存映射
Linux 进程可以使用 mmap 函数来创建新的虚拟内存区域，并将对象映射到这些区域中。

```c
#include <unistd.h>
#include <sys/mman.h>

void *mmap(void *start, size_t length, int prot, int flags, int fd, off_t offset);
```
返回：若成功时则为指向映射区域的指针，若出错则为 MAP_FAILED(-1)

mrnap 函数要求内核创建一个新的虚拟内存区域，最好是从地址 start 开始的一个区
域，并将文件描述符 fd 指定的对象的一个连续的片 (chunk) 映射到这个新的区域。连续的对象片大小为 length 字节，从距文件开始处偏移量为 offset 字节的地方开始。 

start地址仅仅是一个暗示，通常被定义为 NULL。为了我们的目的，我们总是假设起始地址为NULL。图 9-32 描述了这些参数的意义。

![[eDqKLfGvNLCndwWt-1954f4d1-dccc-6689-671d-ec8cb6293d25.png|504]]

参数 prot 包含描述新映射的虚拟内存区域的访问权限位（即在相应区域结构中的 vm_
prot 位）。
- PROT_EXEC: 这个区域内的页面由可以被 CPU 执行的指令组成。
- PROT_READ: 这个区域内的页面可读。
- PROT_WRITE: 这个区域内的页面可写。
- PROT_NONE: 这个区域内的页面不能被访问。

参数 flags 由描述被映射对象类型的位组成。如果设置了 MAP_ANON 标记位，那么被映射的对象就是一个匿名对象，而相应的虚拟页面是请求二进制零的。 MAP_PRIVATE 表示被映射的对象是一个私有的、写时复制的对象，而 MAP_SHARED 表示是一个共享对象。例如
- bufp = Mmap(NULL, size, PROT_READ, MAP_PRIVATE | MAP_ANON, 0, 0);

让内核创建一个新的包含 size 字节的只读、私有、请求二进制零的虚拟内存区域。
如果调用成功，那么 bufp 包含新区域的地址。

## munmap
munmap 函数删除虚拟内存的区域：
```c
#include <unistd.h>
#include <sys/mman.h>

int munmap(void *start, size_t length);
```

返回: 若成功则为 0, 若出错则为-1 。

munmap 函数删除从虚拟地址 start 开始的，由接下来 length 字节组成的区域。

对已删除区域的引用会导致段错误。

# 动态内存分配
虽然可以使用低级的 mmap 和 munmap 函数来创建和删除虚拟内存的区域，但是 C 程序员还是会觉得当运行时需要额外虚拟内存时，用动态内存分配器 (dynamic memory allocator)更方便，也有更好的可移植性 。

动态内存分配器维护着一个进程的虚拟内存区域，称为堆 (heap) (见图 9-33) 。系统之间细节不同，但是不失通用性，假设堆是一个请求二进制零的区域，它紧接在未初始化的数据区域后开始，并向上生长（向更高的地址） 。 对于每个进程，内核维护着一个变量 brk(读做 "break"), 它指向堆的顶部 。

![[eDqKLfGvNLCndwWt-09e3f5dd-8795-edf0-e527-07498a9346f3.png|326]]

分配器将堆视为一组不同大小的块 (block) 的集合来维护 。 每个块就是一个连续的虚拟内存片 (chunk),要么是已分配的，要么是空闲的。已分配的块显式地保留为供应用程序使用。空闲块可用来分配。空闲块保持空闲，直到它显式地被应用所分配 。

一个已分配的块保持已分配状态，直到它被释放，这种释放要么是应用程序显式执行的，要么是内存分配器自身隐式执行的 。

分配器有两种基本风格。两种风格都要求应用显式地分配块。它们的不同之处在于由哪个实体来负责释放已分配的块。
- 显式分配器 (explicit allocator) , 要求应用显式地释放任何已分配的块。例如， C 标准库提供一种叫做 malloc 程序包的显式分配器。 C 程序通过调用 malloc 函数来分配一个块，并通过调用 free 函数来释放一个块。 C++ 中的 new 和 delete 操作符与 C 中的 malloc 和 free 相当 。
- 隐式分配器 (implicit allocator), 另一方面，要求分配器检测一个已分配块何时不再被程序所使用，那么就释放这个块 。 隐式分配器也叫做垃圾收集器 (garbage collector), 而自动释放未使用的已分配的块的过程叫做垃圾收集 (garbage collection) 。例如，诸如 Lisp 、 ML 以及 Java 之类的高级语言就依赖垃圾收集来释放已分配的块 。

## malloc和free函数
C 标准库提供了一个称为 malloc 程序包的显式分配器 。 程序通过调用 malloc 函数来从堆中分配块

```c
#include <stdlib.h>

void *malloc(size_t size);
```

返回：若成功则为已分配块的指针，若出错则为 NULL 。

malloc 函数返回一个指针，指向大小为至少 size 字节的内存块，这个块会为可能包含在这个块内的任何数据对象类型做对齐。实际中，对齐依赖于编译代码在 32 位模式(gee -m32)还是 64 位模式（默认的）中运行。在 32 位模式中， malloe 返回的块的地址总是 8 的倍数。在 64 位模式中，该地址总是 16 的倍数。

如果 malloc 遇到问题（例如，程序要求的内存块比可用的虚拟内存还要大），那么它就返回 NULL, 并设置 errno 。 malloc 不初始化它返回的内存。那些想要已初始化的动态内存的应用程序可以使用 calloc, callee 是一个基千 malloc 的瘦包装函数，它将分配的内存初始化为零。想要改变一个以前已分配块的大小，可以使用 realloc 函数。

动态内存分配器，例如 malloc, 可以通过使用 mmap 和 munmap 函数，显式地分配和释放堆内存，或者还可以使用 sbrk 函数：

```c
#include <unist.h>

void *sbrk(intptr_t incr);
```
返回：若成功则为旧的 brk 指针，若出错则为-1.

sbrk 函数通过将内核的 brk 指针增加 incr 来扩展和收缩堆。如果成功，它就返回brk 的旧值，否则，它就返回 -1, 并将 errno 设置为 ENOMEM。如果 incr 为零，那么sbrk 就返回 brk 的当前值。用一个为负的 incr 来调用 sbrk 是合法的，而且很巧妙，因为返回值(brk 的旧值）指向距新堆顶向上 abs(incr) 字节处。

程序是通过调用 free 函数来释放已分配的堆块。
```c
#include <stdlib.h>

void free(void *ptr);
```

ptr 参数必须指向一个从 malloc 、 calloc 或者 realloc 获得的巳分配块的起始位置。如果不是，那么 free 的行为就是未定义的。更糟的是，既然它什么都不返回， free就不会告诉应用出现了错误。

图 9-34 展示了一个 malloc 和 free 的实现是如何管理一个 C 程序的 16 字的（非常）小的堆的。每个方框代表了一个 4 字节的字。粗线标出的矩形对应于已分配块（有阴影的）和空闲块（无阴影的）。初始时，堆是由一个大小为 16 个字的、双字对齐的、空闲块组成的。（本节中，我们假设分配器返回的块是 8 字节双字边界对齐的。）

![[eDqKLfGvNLCndwWt-2ab9158a-a6da-a680-f16b-544f4bc0c11d.png|410]]

- 图 9-34a: 程序请求一个 4 字的块。 malloc 的响应是：从空闲块的前部切出一个 4字的块，并返回一个指向这个块的第一字的指针。
- 图 9-34b: 程序请求一个 5 字的块。malloc 的响应是：从空闲块的前部分配一个 6 字的块。在本例中， malloc在块里填充了一个额外的字，是为了保持空闲块是双字边界对齐的。
- 图 9-34c: 程序请求一个 6 字的块，而malloc 就从空闲块的前部切出一个 6字的块。
- 图 9-34d: 程序释放在图 9-34b 中分配的那个 6 字的块。注意，在调用 free返回之后，指针 p2 仍然指向被释放了的块。应用有责任在它被一个新的malloc 调用重新初始化之前，不再使用 p2 。
- 图 9-34e: 程序请求一个 2 字的块。在这种情况中， malloc 分配在前一步中被释放了的块的一部分，并返回一个指向这个新块的指针。

## 为什么要使用动态内存分配
用硬编码的大小来分配数组通常不是一种好想法。硬编码数组界限的出现对于拥有百万行代码和大量使用者的大型软件产品而言 ，会变成一场维护的噩梦 。

一种更好的方法是在运行时，在已知了 n 的值之后，动态地分配这个数组。使用这种方法，数组大小的最大值就只由可用的虚拟内存数量来限制了 。

## 分配器的要求和目标
### 要求
显式分配器必须在一些相当严格的约束条件下工作：
- 处理任意请求序列 。 一个应用可以有任意的分配请求和释放请求序列，只要满足约束条件：每个释放请求必须对应于一个当前已分配块，这个块是由一个以前的分配请求获得的。因此，分配器不可以假设分配和释放请求的顺序。例如，分配器不能假设所有的分配请求都有相匹配的释放请求，或者有相匹配的分配和空闲请求是嵌套的 。
- 立即响应请求 。 分配器必须立即响应分配请求 。 因此，不允许分配器为了提高性能重新排列或者缓冲请求 。
- 只使用堆 。 为了使分配器是可扩展的，分配器使用的任何非标量数据结构都必须保存在堆里 。
- 对齐块（对齐要求） 。 分配器必须对齐块，使得它们可以保存任何类型的数据对象。
- 不修改已分配的块。分配器只能操作或者改变空闲块 。 特别是，一旦块被分配了，就不允许修改或者移动它 了。 因此，诸如压缩已分配块这样的技术是不允许使用的。
### 目标
在这些限制条件下，分配器的编写者试图实现吞吐率最大化和内存使用率最大化，而这两个性能目标通常是相互冲突的 。
#### 最大化吞吐率
假定 n 个分配和释放请求的某种序列：R<sub>0</sub>,R<sub>1</sub> .... R<sub>n-1</sub>
吞吐率定义为每个单位时间里完成的请求数。例如，如果一个分配器在 1 秒内完成 500 个分配请求和 500 个释放请求，那么它的吞吐率就是每秒 1000 次操作。

一般而言，我们可以通过使满足分配和释放请求的平均时间最小化来使吞吐率最大化。正如我们会看到的，开发一个具有合理性能的分配器并不困难，所谓合理性能是指一个分配请求的最糟运行时间与空闲块的数量成线性关系，而一个释放请求的运行时间是个常数。

#### 最大化内存利用率
实际上，一个系统中被所有进程分配的虚拟内存的全部数量是受磁盘上交换空间的数最限制的。好的程序员知道虚拟内存是一个有限的空间，必须高效地使用。对于可能被要求分配和释放大块内存的动态内存分配器来说，尤其如此。

有很多方式来描述一个分配器使用堆的效率如何。在我们的经验中，最有用的标准是峰值利用率 (peak utilization) 。像以前一样，我们给定 n 个分配和释放请求的某种顺序
R<sub>0</sub>,R<sub>1</sub> .... R<sub>n-1</sub>

如果一个应用程序请求一个 p 字节的块，那么得到的已分配块的有效载荷 (payload)是 p字节(应用程序所请求的)。在请求R<sub>k</sub>完成之后，聚集有效载荷 (aggregate payload)表示为 p<sub>k</sub> 为当前已分配的块的有效载荷之和，而 H<sub>k</sub>表示堆的当前的（单调非递减的）大小。

![[eDqKLfGvNLCndwWt-205a51e2-2647-929f-9dbc-edd99d23d3ed.png|673]]

分配器的目标就是在整个序列中使峰值利用率 U<sub>n-1</sub> 最大化。正如我们将要看到的，在最大化吞吐率和最大化利用率之间是互相牵制的。特别是，以堆利用率为代价，很容易编写出吞吐率最大化的分配器。分配器设计中一个有趣的挑战就是在两个目标之间找到一个适当的平衡。

## 碎片
### 内部碎片
造成堆利用率很低的主要原因是一种称为碎片 (fragmentation) 的现象，当虽然有未使用的内存但不能用来满足分配请求时，就发生这种现象。有两种形式的碎片：内部碎片(internal fragmentation) 和外部碎片 (external fragmentation) 。

内部碎片是在一个已分配块比有效载荷大时发生的。很多原因都可能造成这个问题。例如，一个分配器的实现可能对已分配块强加一个最小的大小值，而这个大小要比某个请求的有效载荷大。或者，就如我们在图 9-34b 中看到的，分配器可能增加块大小以满足对齐约束条件。

内部碎片的量化是简单明了的。它就是巳分配块大小和它们的有效载荷大小之差的
和。因此，在任意时刻，内部碎片的数最只取决于以前请求的模式和分配器的实现方式。

### 外部碎片
外部碎片是当空闲内存合计起来足够满足一个分配请求，但是没有一个单独的空闲块足够大可以来处理这个请求时发生的。例如，如果图 9-34e 中的请求要求 6 个字，而不是2 个字，那么如果不向内核请求额外的虚拟内存就无法满足这个请求，即使在堆中仍然有6 个空闲的字。问题的产生是由于这 6 个字是分在两个空闲块中的。

外部碎片比内部碎片的量化要困难得多，因为它不仅取决于以前请求的模式和分配器的实现方式，还取决千将来请求的模式。例如，假设在 K 个请求之后，所有空闲块的大小都恰好是 4 个字。这个堆会有外部碎片吗？答案取决于将来请求的模式。如果将来所有的分配请求都要求小于或者等于 4 个字的块，那么就不会有外部碎片。另一方面，如果有一个或者多个请求要求比 4 个字大的块，那么这个堆就会有外部碎片。

因为外部碎片难以量化且不可能预测，所以分配器通常采用启发式策略来试图维持少量的大空闲块，而不是维持大蜇的小空闲块。

## 隐式空闲链表
一个实际的分配器要在吞吐率和利用率之间把握好平衡，就必须考虑以下几个问题：
- 空闲块组织：我们如何记录空闲块？
- 放置：我们如何选择一个合适的空闲块来放置一个新分配的块？
- 分割：在将一个新分配的块放置到某个空闲块之后，我们如何处理这个空闲块中的剩余部分？
- 合并：我们如何处理一个刚刚被释放的块？

任何实际的分配器都需要一些数据结构，允许它来区别块边界，以及区别已分配块和空闲块。大多数分配器将这些信息嵌入块本身。一个简单的方法如图 9-35 所示。

![[eDqKLfGvNLCndwWt-7c047e47-2b50-4724-ae6f-5e3a122ac1e0.png|635]]
### 已分配块和未分配块(空闲块)
在这种情况中，一个块是由一个字的头部、有效载荷，以及可能的一些额外的埃充组成的。头部编码了这个块的大小（包括头部和所有的填充），以及这个块是已分配的还是空闲的。

如果我们强加一个双字的对齐约束条件，那么块大小就总是 8 的倍数，且块大小的最低 3 位总是零。因此，我们只需要内存大小的 29 个高位，释放剩余的 3 位来编码其他信息。

在这种情况中，我们用其中的最低位（已分配位）来指明这个块是已分配的还是空闲的。例如，假设我们有一个已分配的块，大小为 24(0x18)字节(指定的)。那么它的头部将是

![[eDqKLfGvNLCndwWt-d4108802-dd12-fba4-f48d-07a3b9104c80.png|643]]

将已分配块的大小和标志位按位或运算，得到块头部

头部后面就是应用调用 malloc 时请求的有效载荷。有效载荷后面是一片不使用的填充块，其大小可以是任意的。需要填充有很多原因。比如，填充可能是分配器策略的一部分，用来对付外部碎片。或者也需要用它来满足对齐要求。

假设块的格式如图 9-35 所示，我们可以将堆组织为一个连续的已分配块和空闲块的序列，如图 9-36 所示。

![[eDqKLfGvNLCndwWt-64f144cb-7884-1a80-bdcc-cfea432fcc4d.png|857]]

我们称这种结构为隐式空闲链表，是因为空闲块是通过头部中的大小字段隐含地连接着的。分配器可以通过遍历堆中所有的块，从而间接地遍历整个空闲块的集合。注意，我们需要某种特殊标记的结束块，在这个示例中，就是一个设置了已分配位而大小为零的终止头部(terminating header) 。（就像我们将在 9.9. 12 节中看到的，设置已分配位简化了空闲块的合并）

### 隐式空闲链表优缺点
隐式空闲链表的优点是简单。显著的缺点是任何操作的开销，例如放置分配的块，要求对空闲链表进行搜索，该搜索所需时间与堆中已分配块和空闲块的总数呈线性关系。

很重要的一点就是意识到系统对齐要求和分配器对块格式的选择会对分配器上的最小块大小有强制的要求。没有已分配块或者空闲块可以比这个最小值还小。例如，如果我们假设一个双字的对齐要求，那么每个块的大小都必须是双字(8 字节）的倍数。因此，图 9-35 中的块格式就导致最小的块大小为两个字：一个字作头，另一个字维持对齐要求。即使应用只请求一字节，分配器也仍然需要创建一个两字的块。

### 放置已分配的块
当一个应用请求一个 K 字节的块时，分配器搜索空闲链表，查找一个足够大可以放置所请求块的空闲块。分配器执行这种搜索的方式是由放置策略 (placement policy) 确定的。一些常见的策略是首次适配 (first fit) 、下一次适配(next fit) 和最佳适配(best fit) 。

### 适配策略
- 首次适配:从头开始搜索空闲链表，选择第一个合适的空闲块。
- 下一次适配:和首次适配很相似，只不过不是从链表的起始处开始每次搜索，而是从上一次查询结束的地方开始。
- 最佳适配:检查每个空闲块，选择适合所需请求大小的最小空闲块。

### 分割空闲块
一旦分配器找到一个匹配的空闲块，它就必须做另一个策略决定，那就是分配这个空闲块中多少空间。一个选择是用整个空闲块。虽然这种方式简单而快捷，但是主要的缺点就是它会造成内部碎片。如果放置策略趋向于产生好的匹配，那么额外的内部碎片也是可以接受的。

然而，如果匹配不太好，那么分配器通常会选择将这个空闲块分割为两部分。第一部分变成分配块，而剩下的变成一个新的空闲块。图 9-37 展示了分配器如何分割图 9-36 中 8 个字的空闲块，来满足一个应用的对堆内存 3 个字的请求。

![[eDqKLfGvNLCndwWt-24f20a0c-6b68-a443-10e0-c111540363ff.png|827]]

### 获取额外的堆内存
如果分配器不能为请求块找到合适的空闲块将发生什么呢？一个选择是通过合并那些在内存中物理上相邻的空闲块来创建一些更大的空闲块。

然而，如果这样还是不能生成一个足够大的块，或者如果空闲块已经最大程度地合并了，那么分配器就会通过调用 sbrk 函数，向内核请求额外的堆内存。分配器将额外的内存转化成一个大的空闲块，将这个块插入到空闲链表中，然后将被请求的块放置在这个新的空闲块中。

### 合并空闲块
当分配器释放一个已分配块时，可能有其他空闲块与这个新释放的空闲块相邻。这些邻接的空闲块可能引起一种现象，叫做假碎片 (fault fragmentation), 就是有许多可用的空闲块被切割成为小的、无法使用的空闲块。比如，图 9-38 展示了释放图 9-37 中分配的块后得到的结果 。 结果是两个相邻的空闲块，每一个的有效载荷都为 3 个字。因此，接下来一个对 4 字有效载荷的请求就会失败，即使两个空闲块的合计大小足够大，可以满足这个请求。

![[eDqKLfGvNLCndwWt-bbab9430-793f-bf23-a314-651e5d718b50.png|853]]

为了解决假碎片问题，任何实际的分配器都必须合并相邻的空闲块，这个过程称为合并 (coalescing) 。这就出现了一个重要的策略决定，那就是何时执行合并。分配器可以选择立即合并 (immediate coalescing), 也就是在每次一个块被释放时，就合并所有的相邻块。或者它也可以选择推迟合并 (deferred coalescing), 也就是等到某个稍晚的时候再合并空闲块。例如，分配器可以推迟合并，直到某个分配请求失败，然后扫描整个堆，合并所有的空闲块。

### 带边界标记的合井
![[eDqKLfGvNLCndwWt-d535ef61-be47-33eb-4b92-83faf289296b.png|439]]

边界标记(boundary tag), 允许在常数时间内进行对前面块的合并。这种思想，如图 9-39 所示，是在每个块的结尾处添加一个脚部 (footer, 边界标记），其中脚部就是头部的一个副本。

如果每个块包括这样一个脚部，那么分配器就可以通过检查它的脚部，判断前面一个块的起始位置和状态，<font color="#c0504d">这个脚部总是在距当前块开始位置一个字的距离</font> 。也就是说，前脚部和后头部只差一个字节

考虑当分配器释放当前块时所有可能存在的情况：
![[eDqKLfGvNLCndwWt-4d27c0e2-6536-3cca-649b-8ef71039d0d2.png|911]]

m1为前块，n为当前块，m2为后块，图中为当n从已分配块转为空闲块时判断与前块后块合并的情况

边界标记的概念是简单优雅的，它对许多不同类型的分配器和空闲链表组织都是通用的 。 然而，它也存在一个潜在的缺陷 。 它要求每个块都保持一个头部和一个脚部，在应用程序操作许多个小块时，会产生显著的内存开销 。 例如，如果一个图形应用通过反复调用rnalloc 和 free 来动态地创建和销毁图形节点，并且每个图形节点都只要求两个内存字，那么头部和脚部将占用每个已分配块的一半的空间 。

幸运的是，有一种非常聪明的边界标记的优化方法，能够使得在已分配块中不再需要脚部 。 回想一下，当我们试图在内存中合并当前块以及前面的块和后面的块时，只有在前面的块是空闲时，才会需要用到它的脚部。如果我们把前面块的已分配／空闲位存放在当前块中多出来的低位中，那么已分配的块就不需要脚部了，这样我们就可以将这个多出来的空间用作有效载荷了。不过请注意，空闲块仍然需要脚部

## 显示空闲链表
隐式空闲链表通过查看header中的af flag来寻找free chunk，这样做的效率不够高，本文再来说一下显式空闲链表，这是相对隐式空闲链表来说的，显式空闲链表显式的把所有的free chunk通过链表的形式维护起来，也就是memory pool的思想，这样在查找free chunk的时候就不会去查询allocated chunk了，再结合合适的分配算法，时间复杂度能大大降低，工程实践上基本都是使用的基于显式空闲链表的堆管理算法。

使用显示空闲链表，需要在free chunk中加上两个指针字段，一个bk指针指向前面的free chunk，一个fd指针指向后面的free chunk（这两个指针的名字是为了和malloc中的相应数据结构字段名字保持一致），如下图所示，左边是allocated chunk的数据结构，右边是free chunk的数据结构：

![](https://pic3.zhimg.com/80/v2-192d8f524e2a61226337699d46ed736e_720w.webp)

图1

图1的基本数据结构可以继续根据[隐式空闲链表](https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzg5MzU4NTU5Nw%3D%3D%26mid%3D2247483842%26idx%3D1%26sn%3D5bf65cab40a6243f462bfcf433394294%26chksm%3Dc02dd010f75a59064176fc681a53a2594f23b5760185c625070ff7e27a1c3a5ee9dc272b7371%26scene%3D21%23wechat_redirect)中介绍的方法改进，即去掉allocated chunk中的footer部分，这样可以进一步提高内存利用率，如下图：

![](https://pic1.zhimg.com/80/v2-950defc0d649552cdc5a05524dbf43f4_720w.webp)

图2

通过图2中的free chunk中的fd、bk指针，可以很容易把堆中所有的free chunk组织成一个双向链表，分配、合并free chunk的方法与[隐式空闲链表](https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzg5MzU4NTU5Nw%3D%3D%26mid%3D2247483842%26idx%3D1%26sn%3D5bf65cab40a6243f462bfcf433394294%26chksm%3Dc02dd010f75a59064176fc681a53a2594f23b5760185c625070ff7e27a1c3a5ee9dc272b7371%26scene%3D21%23wechat_redirect)中的方法相同，不同之处只是需要在链表改变时维护一下这两个指针的值，这个很简单就不赘述了。这种只使用单个链表的算法只是为了帮助理解后面的算法，实际工程基本都是使用多个链表来管理堆

### 简单分离存储
这种算法把所有的free chunk用多个单向链表来维护，每个链表维护一组大小相同的free chunk，如下图所示（假设相邻链表的chunk大小相差16字节）：

![](https://pic2.zhimg.com/80/v2-2307f23e55d4029b9eceffc781550595_720w.webp)

图3

这种算法使用单链表即可，因为分配和释放都是操作链表头，释放allocated chunk的时候也不要求进行合并操作，所以chunk的数据结构不需要af flag和footer，可以简化为下图所示：

![](https://pic1.zhimg.com/80/v2-75415f13a60aa2a58fbed2afd271bd24_720w.webp)

图4

以上图为例，当我们需要分配一个20字节的free chunk的时候，需要从大小为32的链表中分配chunk，如果该链表非空，直接分配取链表第一个chunk，如果链表为空，需要通过前文《[内存管理：虚拟地址空间和堆](https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzg5MzU4NTU5Nw%3D%3D%26mid%3D2247483831%26idx%3D1%26sn%3D57d361e5dffe0e59117d12bfd3602d3f%26chksm%3Dc02dd065f75a59733bf86cf1a9faeecb479c8570f84d2e72892ed8e41b8769ec57e456aba687%26scene%3D21%23wechat_redirect)》介绍的brk、sbrk、mmap方法向操作系统申请一块空间，均分成若干个大小为32的chunk，维护到相应大小的空闲链表上，这种算法的优点是分配和释放chunk的时间复杂度为O(1)，缺点是内存利用率偏低。

### 分离适配
和简单分离存储相比，这种算法虽然也是维护多个空闲链表，但是每个空闲链表的chunk大小都在一个定好的范围之内，不要求同一空闲链表的chunk size都相同，如下图所示：

![](https://pic1.zhimg.com/80/v2-9c4bf602289ce7f948d2d7b1f2e39a88_720w.webp)

图5

为了分配一个chunk，要先确定使用请求的大小在哪一个空闲链表上，然后再在所在的链表上使用first fit、last fit、best fit这些算法来确定具体分配哪个chunk，以上面图5为例，分两种情况讨论：

1. 相应list为空：假如用户请求2049个字节，加上4字节的header，再进行8字节对齐，实际需要分配2056个字节，而[2049,4096]这个list为空，这时候需要从系统中申请一块足够大的空间，假如申请4096大小的空间，然后分成2056和2040两个chunk，把2056的chunk返回给用户，2040的chunk维护到相应的list上。
2. 相应list不为空：假如用户请求1601个字节，加上4字节的header，再进行8字节对齐，实际需要分配1608个字节，这时候需要查询[1024,2048]这个list，里面只有一个2048大小的chunk，那就把这个chunk拆分成1608和440两个chunk，把1608的chunk返回给用户，440的chunk维护到相应的list中。

释放allocated chunk的时候要进行合并，并把合并后的chunk维护到相应的list上，合并过程在[隐式空闲链表](https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzg5MzU4NTU5Nw%3D%3D%26mid%3D2247483842%26idx%3D1%26sn%3D5bf65cab40a6243f462bfcf433394294%26chksm%3Dc02dd010f75a59064176fc681a53a2594f23b5760185c625070ff7e27a1c3a5ee9dc272b7371%26scene%3D21%23wechat_redirect)中已经说过，这里不再赘述了。分离适配方法是一种常见的选择，malloc就用到了这个方法，当然具体实现比这里讲的要复杂的多的多，malloc也没有只使用这一种算法，后续讲malloc实现的时候再具体讲。

### 伙伴系统

说伙伴系统可能好多人感觉这个名词陌生，其实就是buddy system，英文的说法更常用。它是上面分离适配的一种特殊情况，所有的chunk size都为2的幂次方，如下图所示：

![](https://pic2.zhimg.com/80/v2-f5b2cddb3db5194414660c8e6e4ba939_720w.webp)

图6

假如用户请求99字节，先加上4字节的header之后进行8字节对齐，这时候为104，buddy system的算法要求这个数还要继续往上舍入到最接近的2的幂次方，也就是128（2的7次方），以图6为例，需要查询图中第三行那个list，采用first fit的话，找到2的8次方那个chunk，这时候递归二等分这个chunk，直到得到128大小，在二等分的过程中，每个剩下的那一半（叫buddy，这就是buddy system名字的由来）被放置到相应的空闲链表中。相应的合并过程也类似，不再赘述了。

从前面示例中buddy system二等分这个关键特性，给定地址和chunk size，就可以很容易算出它的buddy的地址，因为一个chunk的地址和它的buddy地址只有一位不同，以前面的128大小的chunk为例，它的地址为：

xxx...x00000000

它的buddy的地址为：

xxx...x10000000

所以buddy system的chunk结构可以优化为下面形式，可以看到里面没有footer部分了：

![](https://pic4.zhimg.com/80/v2-a0eae5b64a4ebff99d9be9e44b2bcb73_720w.webp)

图7

buddy system的主要优点是快速搜索和快速合并，主要缺点是chunk size为2的幂次方可能会导致显著的内部碎片，所以它不适用于通用目的的memory管理，但如果有一些需要chunk size是2的幂次方的特殊场景，这种算法会是一个好选择